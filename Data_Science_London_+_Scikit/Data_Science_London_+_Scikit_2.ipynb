{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data Science London + Scikit 2.ipynb",
      "version": "0.3.2",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "nm84dw3GF5Zq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.model_selection import cross_val_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JlGrmttIF-l-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = pd.read_csv('train.csv',header = None)\n",
        "train_labels = pd.read_csv('trainLabels.csv',header = None)\n",
        "test_data =  pd.read_csv('test.csv',header = None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuY_i7SIGABO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "5a83b063-f940-41a2-fbff-eaa4dba0899b"
      },
      "source": [
        "train_data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.299403</td>\n",
              "      <td>-1.226624</td>\n",
              "      <td>1.498425</td>\n",
              "      <td>-1.176150</td>\n",
              "      <td>5.289853</td>\n",
              "      <td>0.208297</td>\n",
              "      <td>2.404498</td>\n",
              "      <td>1.594506</td>\n",
              "      <td>-0.051608</td>\n",
              "      <td>0.663234</td>\n",
              "      <td>-1.408370</td>\n",
              "      <td>1.114744</td>\n",
              "      <td>0.910415</td>\n",
              "      <td>2.218110</td>\n",
              "      <td>4.305643</td>\n",
              "      <td>0.088924</td>\n",
              "      <td>0.169149</td>\n",
              "      <td>0.413448</td>\n",
              "      <td>1.513862</td>\n",
              "      <td>2.662967</td>\n",
              "      <td>-1.072765</td>\n",
              "      <td>0.149111</td>\n",
              "      <td>0.559579</td>\n",
              "      <td>4.378885</td>\n",
              "      <td>-0.463603</td>\n",
              "      <td>-0.063959</td>\n",
              "      <td>0.544930</td>\n",
              "      <td>0.712772</td>\n",
              "      <td>-1.494050</td>\n",
              "      <td>-2.636169</td>\n",
              "      <td>-0.850465</td>\n",
              "      <td>-0.622990</td>\n",
              "      <td>-1.833057</td>\n",
              "      <td>0.293024</td>\n",
              "      <td>3.552681</td>\n",
              "      <td>0.717611</td>\n",
              "      <td>3.305972</td>\n",
              "      <td>-2.715559</td>\n",
              "      <td>-2.682409</td>\n",
              "      <td>0.101050</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.174176</td>\n",
              "      <td>0.332157</td>\n",
              "      <td>0.949919</td>\n",
              "      <td>-1.285328</td>\n",
              "      <td>2.199061</td>\n",
              "      <td>-0.151268</td>\n",
              "      <td>-0.427039</td>\n",
              "      <td>2.619246</td>\n",
              "      <td>-0.765884</td>\n",
              "      <td>-0.093780</td>\n",
              "      <td>0.935347</td>\n",
              "      <td>1.057796</td>\n",
              "      <td>-0.539275</td>\n",
              "      <td>-0.172662</td>\n",
              "      <td>-0.679051</td>\n",
              "      <td>0.607362</td>\n",
              "      <td>1.148635</td>\n",
              "      <td>2.437077</td>\n",
              "      <td>-0.313069</td>\n",
              "      <td>0.528104</td>\n",
              "      <td>-0.513476</td>\n",
              "      <td>0.766221</td>\n",
              "      <td>-1.466939</td>\n",
              "      <td>-2.318885</td>\n",
              "      <td>1.647223</td>\n",
              "      <td>-1.556443</td>\n",
              "      <td>-1.645581</td>\n",
              "      <td>-0.198467</td>\n",
              "      <td>-1.472066</td>\n",
              "      <td>-1.906147</td>\n",
              "      <td>-0.819750</td>\n",
              "      <td>0.012037</td>\n",
              "      <td>2.038836</td>\n",
              "      <td>0.468579</td>\n",
              "      <td>-0.517657</td>\n",
              "      <td>0.422326</td>\n",
              "      <td>0.803699</td>\n",
              "      <td>1.213219</td>\n",
              "      <td>1.382932</td>\n",
              "      <td>-1.817761</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.192222</td>\n",
              "      <td>-0.414371</td>\n",
              "      <td>0.067054</td>\n",
              "      <td>-2.233568</td>\n",
              "      <td>3.658881</td>\n",
              "      <td>0.089007</td>\n",
              "      <td>0.203439</td>\n",
              "      <td>-4.219054</td>\n",
              "      <td>-1.184919</td>\n",
              "      <td>-1.240310</td>\n",
              "      <td>-0.890270</td>\n",
              "      <td>0.909969</td>\n",
              "      <td>-11.851312</td>\n",
              "      <td>3.352420</td>\n",
              "      <td>-4.862125</td>\n",
              "      <td>-0.903317</td>\n",
              "      <td>-1.824344</td>\n",
              "      <td>0.045446</td>\n",
              "      <td>-2.126474</td>\n",
              "      <td>1.161563</td>\n",
              "      <td>-1.027912</td>\n",
              "      <td>-1.078792</td>\n",
              "      <td>1.848525</td>\n",
              "      <td>3.758918</td>\n",
              "      <td>0.623649</td>\n",
              "      <td>-0.091044</td>\n",
              "      <td>-1.033094</td>\n",
              "      <td>-0.254151</td>\n",
              "      <td>-4.377542</td>\n",
              "      <td>-1.196298</td>\n",
              "      <td>-0.604501</td>\n",
              "      <td>0.750054</td>\n",
              "      <td>-3.360521</td>\n",
              "      <td>0.856988</td>\n",
              "      <td>-2.751451</td>\n",
              "      <td>-1.582735</td>\n",
              "      <td>1.672246</td>\n",
              "      <td>0.656438</td>\n",
              "      <td>-0.932473</td>\n",
              "      <td>2.987436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.573270</td>\n",
              "      <td>-0.580318</td>\n",
              "      <td>-0.866332</td>\n",
              "      <td>-0.603812</td>\n",
              "      <td>3.125716</td>\n",
              "      <td>0.870321</td>\n",
              "      <td>-0.161992</td>\n",
              "      <td>4.499666</td>\n",
              "      <td>1.038741</td>\n",
              "      <td>-1.092716</td>\n",
              "      <td>-0.713474</td>\n",
              "      <td>-0.136399</td>\n",
              "      <td>0.058990</td>\n",
              "      <td>-1.083458</td>\n",
              "      <td>1.622659</td>\n",
              "      <td>-1.685582</td>\n",
              "      <td>-1.222879</td>\n",
              "      <td>-0.215834</td>\n",
              "      <td>0.155612</td>\n",
              "      <td>0.627873</td>\n",
              "      <td>-0.732789</td>\n",
              "      <td>1.337941</td>\n",
              "      <td>1.335689</td>\n",
              "      <td>0.680062</td>\n",
              "      <td>0.504754</td>\n",
              "      <td>1.204808</td>\n",
              "      <td>0.144477</td>\n",
              "      <td>0.673993</td>\n",
              "      <td>1.027921</td>\n",
              "      <td>3.073382</td>\n",
              "      <td>1.022959</td>\n",
              "      <td>1.275598</td>\n",
              "      <td>-3.480110</td>\n",
              "      <td>-1.065252</td>\n",
              "      <td>2.153133</td>\n",
              "      <td>1.563539</td>\n",
              "      <td>2.767117</td>\n",
              "      <td>0.215748</td>\n",
              "      <td>0.619645</td>\n",
              "      <td>1.883397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.613071</td>\n",
              "      <td>-0.644204</td>\n",
              "      <td>1.112558</td>\n",
              "      <td>-0.032397</td>\n",
              "      <td>3.490142</td>\n",
              "      <td>-0.011935</td>\n",
              "      <td>1.443521</td>\n",
              "      <td>-4.290282</td>\n",
              "      <td>-1.761308</td>\n",
              "      <td>0.807652</td>\n",
              "      <td>-0.416575</td>\n",
              "      <td>0.433862</td>\n",
              "      <td>-12.822821</td>\n",
              "      <td>-0.048248</td>\n",
              "      <td>-5.031497</td>\n",
              "      <td>-0.704413</td>\n",
              "      <td>0.515952</td>\n",
              "      <td>-2.635899</td>\n",
              "      <td>-2.359881</td>\n",
              "      <td>-0.053400</td>\n",
              "      <td>0.741432</td>\n",
              "      <td>1.573043</td>\n",
              "      <td>0.723686</td>\n",
              "      <td>1.735602</td>\n",
              "      <td>0.335774</td>\n",
              "      <td>0.572905</td>\n",
              "      <td>0.625971</td>\n",
              "      <td>0.412084</td>\n",
              "      <td>-4.883833</td>\n",
              "      <td>-5.588332</td>\n",
              "      <td>0.513906</td>\n",
              "      <td>-1.803473</td>\n",
              "      <td>0.518579</td>\n",
              "      <td>-0.205029</td>\n",
              "      <td>-4.744566</td>\n",
              "      <td>-1.520015</td>\n",
              "      <td>1.830651</td>\n",
              "      <td>0.870772</td>\n",
              "      <td>-1.894609</td>\n",
              "      <td>0.408332</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         0         1         2   ...        37        38        39\n",
              "0  0.299403 -1.226624  1.498425  ... -2.715559 -2.682409  0.101050\n",
              "1 -1.174176  0.332157  0.949919  ...  1.213219  1.382932 -1.817761\n",
              "2  1.192222 -0.414371  0.067054  ...  0.656438 -0.932473  2.987436\n",
              "3  1.573270 -0.580318 -0.866332  ...  0.215748  0.619645  1.883397\n",
              "4 -0.613071 -0.644204  1.112558  ...  0.870772 -1.894609  0.408332\n",
              "\n",
              "[5 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psNzjASpGAD2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "295a416f-0a6d-4afd-dc64-a296d3307cd4"
      },
      "source": [
        "train_data.shape,test_data.shape,train_labels.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((1000, 40), (9000, 40), (1000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSAHSsxHGAGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "outputId": "98f2fb13-6325-4c40-eeb5-4510a72a7002"
      },
      "source": [
        "train_data.describe()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.025596</td>\n",
              "      <td>-0.024526</td>\n",
              "      <td>-0.024088</td>\n",
              "      <td>-0.002271</td>\n",
              "      <td>1.092329</td>\n",
              "      <td>-0.006250</td>\n",
              "      <td>0.497342</td>\n",
              "      <td>-0.037883</td>\n",
              "      <td>0.026391</td>\n",
              "      <td>-0.003597</td>\n",
              "      <td>-0.016250</td>\n",
              "      <td>-0.038010</td>\n",
              "      <td>-1.985616</td>\n",
              "      <td>0.012374</td>\n",
              "      <td>-0.029229</td>\n",
              "      <td>-0.039307</td>\n",
              "      <td>-0.004091</td>\n",
              "      <td>-0.032836</td>\n",
              "      <td>0.428313</td>\n",
              "      <td>0.043427</td>\n",
              "      <td>0.073461</td>\n",
              "      <td>-0.005140</td>\n",
              "      <td>0.912288</td>\n",
              "      <td>0.902301</td>\n",
              "      <td>-0.023110</td>\n",
              "      <td>0.047473</td>\n",
              "      <td>-0.041117</td>\n",
              "      <td>0.012985</td>\n",
              "      <td>-0.395782</td>\n",
              "      <td>0.123921</td>\n",
              "      <td>0.030651</td>\n",
              "      <td>0.022951</td>\n",
              "      <td>-0.542491</td>\n",
              "      <td>-0.011608</td>\n",
              "      <td>-0.483507</td>\n",
              "      <td>0.033371</td>\n",
              "      <td>0.567185</td>\n",
              "      <td>0.006849</td>\n",
              "      <td>-0.892659</td>\n",
              "      <td>0.609451</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.008282</td>\n",
              "      <td>1.016298</td>\n",
              "      <td>0.979109</td>\n",
              "      <td>0.970575</td>\n",
              "      <td>4.538834</td>\n",
              "      <td>0.989128</td>\n",
              "      <td>2.118819</td>\n",
              "      <td>2.232256</td>\n",
              "      <td>1.001064</td>\n",
              "      <td>1.013520</td>\n",
              "      <td>1.026325</td>\n",
              "      <td>0.985889</td>\n",
              "      <td>4.528096</td>\n",
              "      <td>0.995652</td>\n",
              "      <td>2.164547</td>\n",
              "      <td>1.002481</td>\n",
              "      <td>0.970401</td>\n",
              "      <td>1.000130</td>\n",
              "      <td>2.176020</td>\n",
              "      <td>0.987689</td>\n",
              "      <td>0.967282</td>\n",
              "      <td>0.980319</td>\n",
              "      <td>2.178778</td>\n",
              "      <td>4.241903</td>\n",
              "      <td>1.019566</td>\n",
              "      <td>0.995752</td>\n",
              "      <td>0.998182</td>\n",
              "      <td>1.030610</td>\n",
              "      <td>2.296818</td>\n",
              "      <td>2.410453</td>\n",
              "      <td>1.011645</td>\n",
              "      <td>1.001375</td>\n",
              "      <td>2.239939</td>\n",
              "      <td>1.022456</td>\n",
              "      <td>2.121281</td>\n",
              "      <td>1.007044</td>\n",
              "      <td>2.227876</td>\n",
              "      <td>0.997635</td>\n",
              "      <td>2.022022</td>\n",
              "      <td>2.045439</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-3.365711</td>\n",
              "      <td>-3.492086</td>\n",
              "      <td>-2.695602</td>\n",
              "      <td>-3.460471</td>\n",
              "      <td>-16.421901</td>\n",
              "      <td>-3.041250</td>\n",
              "      <td>-7.224761</td>\n",
              "      <td>-6.509084</td>\n",
              "      <td>-3.145588</td>\n",
              "      <td>-2.749812</td>\n",
              "      <td>-3.304074</td>\n",
              "      <td>-3.157436</td>\n",
              "      <td>-14.706080</td>\n",
              "      <td>-3.002151</td>\n",
              "      <td>-6.790633</td>\n",
              "      <td>-2.914729</td>\n",
              "      <td>-3.464048</td>\n",
              "      <td>-2.944093</td>\n",
              "      <td>-8.258306</td>\n",
              "      <td>-3.423875</td>\n",
              "      <td>-4.251382</td>\n",
              "      <td>-2.822644</td>\n",
              "      <td>-6.337522</td>\n",
              "      <td>-16.156070</td>\n",
              "      <td>-3.218446</td>\n",
              "      <td>-2.820792</td>\n",
              "      <td>-3.023811</td>\n",
              "      <td>-3.054384</td>\n",
              "      <td>-8.034421</td>\n",
              "      <td>-7.105723</td>\n",
              "      <td>-3.379194</td>\n",
              "      <td>-2.971125</td>\n",
              "      <td>-7.840890</td>\n",
              "      <td>-2.999564</td>\n",
              "      <td>-7.124105</td>\n",
              "      <td>-2.952358</td>\n",
              "      <td>-5.452254</td>\n",
              "      <td>-3.473913</td>\n",
              "      <td>-8.051722</td>\n",
              "      <td>-7.799086</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>-0.669010</td>\n",
              "      <td>-0.693937</td>\n",
              "      <td>-0.698830</td>\n",
              "      <td>-0.617557</td>\n",
              "      <td>-1.801997</td>\n",
              "      <td>-0.732265</td>\n",
              "      <td>-0.838619</td>\n",
              "      <td>-1.604037</td>\n",
              "      <td>-0.677562</td>\n",
              "      <td>-0.682220</td>\n",
              "      <td>-0.713704</td>\n",
              "      <td>-0.730293</td>\n",
              "      <td>-5.094964</td>\n",
              "      <td>-0.694081</td>\n",
              "      <td>-1.441443</td>\n",
              "      <td>-0.757619</td>\n",
              "      <td>-0.668335</td>\n",
              "      <td>-0.727001</td>\n",
              "      <td>-0.983595</td>\n",
              "      <td>-0.594638</td>\n",
              "      <td>-0.588171</td>\n",
              "      <td>-0.698036</td>\n",
              "      <td>-0.542526</td>\n",
              "      <td>-1.822188</td>\n",
              "      <td>-0.720837</td>\n",
              "      <td>-0.617001</td>\n",
              "      <td>-0.668062</td>\n",
              "      <td>-0.696411</td>\n",
              "      <td>-1.936374</td>\n",
              "      <td>-1.562374</td>\n",
              "      <td>-0.659457</td>\n",
              "      <td>-0.696032</td>\n",
              "      <td>-2.121943</td>\n",
              "      <td>-0.664550</td>\n",
              "      <td>-1.879247</td>\n",
              "      <td>-0.642861</td>\n",
              "      <td>-1.059786</td>\n",
              "      <td>-0.691162</td>\n",
              "      <td>-2.220126</td>\n",
              "      <td>-0.565041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.027895</td>\n",
              "      <td>-0.033194</td>\n",
              "      <td>0.008145</td>\n",
              "      <td>0.002327</td>\n",
              "      <td>0.862818</td>\n",
              "      <td>0.027041</td>\n",
              "      <td>0.582321</td>\n",
              "      <td>0.018809</td>\n",
              "      <td>0.022092</td>\n",
              "      <td>-0.036110</td>\n",
              "      <td>0.019479</td>\n",
              "      <td>-0.075950</td>\n",
              "      <td>-2.103532</td>\n",
              "      <td>-0.005946</td>\n",
              "      <td>-0.033219</td>\n",
              "      <td>-0.019046</td>\n",
              "      <td>0.008360</td>\n",
              "      <td>-0.011366</td>\n",
              "      <td>0.488217</td>\n",
              "      <td>0.082688</td>\n",
              "      <td>0.094307</td>\n",
              "      <td>-0.004404</td>\n",
              "      <td>1.050071</td>\n",
              "      <td>0.970403</td>\n",
              "      <td>-0.012183</td>\n",
              "      <td>0.014636</td>\n",
              "      <td>-0.017535</td>\n",
              "      <td>0.039219</td>\n",
              "      <td>-0.489296</td>\n",
              "      <td>-0.040604</td>\n",
              "      <td>0.049416</td>\n",
              "      <td>0.049778</td>\n",
              "      <td>-0.568262</td>\n",
              "      <td>-0.028097</td>\n",
              "      <td>-0.493575</td>\n",
              "      <td>0.037732</td>\n",
              "      <td>0.455474</td>\n",
              "      <td>0.038284</td>\n",
              "      <td>-0.855470</td>\n",
              "      <td>0.779944</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>0.762520</td>\n",
              "      <td>0.682753</td>\n",
              "      <td>0.661434</td>\n",
              "      <td>0.640743</td>\n",
              "      <td>3.843172</td>\n",
              "      <td>0.671456</td>\n",
              "      <td>1.913664</td>\n",
              "      <td>1.438304</td>\n",
              "      <td>0.741310</td>\n",
              "      <td>0.665364</td>\n",
              "      <td>0.709416</td>\n",
              "      <td>0.644553</td>\n",
              "      <td>1.186164</td>\n",
              "      <td>0.664921</td>\n",
              "      <td>1.492611</td>\n",
              "      <td>0.678748</td>\n",
              "      <td>0.674583</td>\n",
              "      <td>0.588732</td>\n",
              "      <td>1.915022</td>\n",
              "      <td>0.711525</td>\n",
              "      <td>0.727896</td>\n",
              "      <td>0.673427</td>\n",
              "      <td>2.367748</td>\n",
              "      <td>3.825862</td>\n",
              "      <td>0.671318</td>\n",
              "      <td>0.731892</td>\n",
              "      <td>0.642797</td>\n",
              "      <td>0.706336</td>\n",
              "      <td>1.044188</td>\n",
              "      <td>1.614308</td>\n",
              "      <td>0.747031</td>\n",
              "      <td>0.699917</td>\n",
              "      <td>0.939348</td>\n",
              "      <td>0.651374</td>\n",
              "      <td>1.005795</td>\n",
              "      <td>0.691800</td>\n",
              "      <td>2.122157</td>\n",
              "      <td>0.693535</td>\n",
              "      <td>0.388698</td>\n",
              "      <td>1.992193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>3.326246</td>\n",
              "      <td>3.583870</td>\n",
              "      <td>2.546507</td>\n",
              "      <td>3.088738</td>\n",
              "      <td>17.565345</td>\n",
              "      <td>3.102997</td>\n",
              "      <td>7.592666</td>\n",
              "      <td>7.130097</td>\n",
              "      <td>3.145258</td>\n",
              "      <td>3.919426</td>\n",
              "      <td>3.409653</td>\n",
              "      <td>3.253032</td>\n",
              "      <td>12.186445</td>\n",
              "      <td>3.737423</td>\n",
              "      <td>6.959736</td>\n",
              "      <td>3.100935</td>\n",
              "      <td>2.805197</td>\n",
              "      <td>3.291544</td>\n",
              "      <td>7.074432</td>\n",
              "      <td>3.343812</td>\n",
              "      <td>2.938033</td>\n",
              "      <td>3.053262</td>\n",
              "      <td>8.096838</td>\n",
              "      <td>14.373681</td>\n",
              "      <td>2.981582</td>\n",
              "      <td>3.662800</td>\n",
              "      <td>3.293911</td>\n",
              "      <td>3.069885</td>\n",
              "      <td>7.413173</td>\n",
              "      <td>8.812739</td>\n",
              "      <td>2.844792</td>\n",
              "      <td>3.688047</td>\n",
              "      <td>7.160379</td>\n",
              "      <td>3.353631</td>\n",
              "      <td>6.005818</td>\n",
              "      <td>3.420561</td>\n",
              "      <td>6.603499</td>\n",
              "      <td>3.492548</td>\n",
              "      <td>5.774120</td>\n",
              "      <td>6.803984</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                0            1   ...           38           39\n",
              "count  1000.000000  1000.000000  ...  1000.000000  1000.000000\n",
              "mean      0.025596    -0.024526  ...    -0.892659     0.609451\n",
              "std       1.008282     1.016298  ...     2.022022     2.045439\n",
              "min      -3.365711    -3.492086  ...    -8.051722    -7.799086\n",
              "25%      -0.669010    -0.693937  ...    -2.220126    -0.565041\n",
              "50%       0.027895    -0.033194  ...    -0.855470     0.779944\n",
              "75%       0.762520     0.682753  ...     0.388698     1.992193\n",
              "max       3.326246     3.583870  ...     5.774120     6.803984\n",
              "\n",
              "[8 rows x 40 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEgaPtC5GAJr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "211b6895-adc4-4356-8e7a-0a94e5fd3af0"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test = train_test_split(train_data,train_labels, test_size = 0.30, random_state = 101)\n",
        "x_train.shape,x_test.shape,y_train.shape,y_test.shape"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((700, 40), (300, 40), (700, 1), (300, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T6xmDsvUGARF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "2cac5292-590c-4c57-c62b-499dd527565e"
      },
      "source": [
        "# NAIBE BAYES\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "model = GaussianNB()\n",
        "model.fit(x_train,y_train.values.ravel())\n",
        "predicted= model.predict(x_test)\n",
        "print('Naive Bayes',accuracy_score(y_test, predicted))\n",
        "\n",
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier()\n",
        "knn_model.fit(x_train,y_train.values.ravel())\n",
        "predicted= knn_model.predict(x_test)\n",
        "print('KNN',accuracy_score(y_test, predicted))\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
        "rfc_model.fit(x_train,y_train.values.ravel())\n",
        "predicted = rfc_model.predict(x_test)\n",
        "print('Random Forest',accuracy_score(y_test,predicted))\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(solver = 'saga')\n",
        "lr_model.fit(x_train,y_train.values.ravel())\n",
        "lr_predicted = lr_model.predict(x_test)\n",
        "print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC(gamma = 'auto')\n",
        "svc_model.fit(x_train,y_train.values.ravel())\n",
        "svc_predicted = svc_model.predict(x_test)\n",
        "print('SVM',accuracy_score(y_test, svc_predicted))\n",
        "\n",
        "#DECISON TREE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree_model = DecisionTreeClassifier()\n",
        "dtree_model.fit(x_train,y_train.values.ravel())\n",
        "dtree_predicted = dtree_model.predict(x_test)\n",
        "print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
        "\n",
        "#XGBOOST\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "xgb.fit(x_train,y_train.values.ravel())\n",
        "xgb_predicted = xgb.predict(x_test)\n",
        "print('XGBoost',accuracy_score(y_test, xgb_predicted))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes 0.8066666666666666\n",
            "KNN 0.9166666666666666\n",
            "Random Forest 0.86\n",
            "Logistic Regression 0.82\n",
            "SVM 0.9033333333333333\n",
            "Decision Tree 0.73\n",
            "XGBoost 0.87\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXaLJDrkGAhA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler, Normalizer\n",
        "\n",
        "norm = Normalizer()\n",
        "#x_norm_train = norm.fit_transform(x_train)\n",
        "#x_norm_test = norm.transform(x_test)\n",
        "norm_train_data = norm.fit_transform(train_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnCj2Ik-GAkQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "94857647-4bde-4a3e-9c12-5c5620939ad6"
      },
      "source": [
        "# NAIBE BAYES\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "#nb_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#nb_predicted= nb_model.predict(x_norm_test)\n",
        "#print('Naive Bayes',accuracy_score(y_test, nb_predicted))\n",
        "print('Naive Bayes',cross_val_score(nb_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
        "#knn_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#knn_predicted= knn_model.predict(x_norm_test)\n",
        "#print('KNN',accuracy_score(y_test, knn_predicted))\n",
        "print('KNN',cross_val_score(knn_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
        "#rfc_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
        "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
        "print('Random Forest',cross_val_score(rfc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(solver = 'saga')\n",
        "#lr_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#lr_predicted = lr_model.predict(x_norm_test)\n",
        "#print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
        "print('Logistic Regression',cross_val_score(lr_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC(gamma = 'auto')\n",
        "#svc_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#svc_predicted = svc_model.predict(x_norm_test)\n",
        "#print('SVM',accuracy_score(y_test, svc_predicted))\n",
        "print('SVM',cross_val_score(svc_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#DECISON TREE\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree_model = DecisionTreeClassifier()\n",
        "#dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#dtree_predicted = dtree_model.predict(x_norm_test)\n",
        "#print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
        "print('Decision Tree',cross_val_score(dtree_model,norm_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#XGBOOST\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "#xgb.fit(x_norm_train,y_train.values.ravel())\n",
        "#xgb_predicted = xgb.predict(x_norm_test)\n",
        "#print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
        "print('XGBoost',cross_val_score(xgb,norm_train_data, train_labels.values.ravel(), cv=10).mean())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes 0.808\n",
            "KNN 0.9019999999999999\n",
            "Random Forest 0.8699999999999999\n",
            "Logistic Regression 0.8220000000000001\n",
            "SVM 0.808\n",
            "Decision Tree 0.796\n",
            "XGBoost 0.8710000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t9QhbSxqGAnc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "5b3e3a61-6328-4ad6-dbb4-24980fcc339c"
      },
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pca  = PCA(n_components=12)\n",
        "#x_train = pca.fit_transform(x_train)\n",
        "#x_test = pca.transform(x_test)\n",
        "pca_train_data = pca.fit_transform(train_data)\n",
        "explained_variance = pca.explained_variance_ratio_ \n",
        "print(explained_variance)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.25054403 0.2055048  0.08026473 0.05033658 0.04895951 0.04489903\n",
            " 0.0417078  0.03127933 0.02309793 0.02099955 0.01618869 0.01264833]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FI_StYFqGAe9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a19f7bcd-1316-4c9e-a59e-ac8f91c203d1"
      },
      "source": [
        "pca_train_data.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 12)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OuCJtsrGAc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "outputId": "1798c3b6-7438-42f6-fc84-8822c77870ad"
      },
      "source": [
        "# NAIBE BAYES\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "nb_model = GaussianNB()\n",
        "#nb_model.fit(pca_train_data,y_train.values.ravel())\n",
        "#nb_predicted= nb_model.predict(x_norm_test)\n",
        "#print('Naive Bayes',accuracy_score(y_test, nb_predicted))\n",
        "print('Naive Bayes',cross_val_score(nb_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#KNN\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn_model = KNeighborsClassifier(n_neighbors = 5)\n",
        "#knn_model.fit(pca_train_data,y_train.values.ravel())\n",
        "#knn_predicted= knn_model.predict(x_norm_test)\n",
        "#print('KNN',accuracy_score(y_test, knn_predicted))\n",
        "print('KNN',cross_val_score(knn_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#RANDOM FOREST\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "rfc_model = RandomForestClassifier(n_estimators = 100,random_state = 99)\n",
        "#rfc_model.fit(pca_train_data,y_train.values.ravel())\n",
        "#rfc_predicted = rfc_model.predict(x_norm_test)\n",
        "#print('Random Forest',accuracy_score(y_test,rfc_predicted))\n",
        "print('Random Forest',cross_val_score(rfc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#LOGISTIC REGRESSION\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "lr_model = LogisticRegression(solver = 'saga')\n",
        "#lr_model.fit(pca_train_data,y_train.values.ravel())\n",
        "#lr_predicted = lr_model.predict(x_norm_test)\n",
        "#print('Logistic Regression',accuracy_score(y_test, lr_predicted))\n",
        "print('Logistic Regression',cross_val_score(lr_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#SVM\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svc_model = SVC(gamma = 'auto')\n",
        "#svc_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#svc_predicted = svc_model.predict(x_norm_test)\n",
        "#print('SVM',accuracy_score(y_test, svc_predicted))\n",
        "print('SVM',cross_val_score(svc_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#DECISON TREE\n",
        "\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "dtree_model = DecisionTreeClassifier()\n",
        "#dtree_model.fit(x_norm_train,y_train.values.ravel())\n",
        "#dtree_predicted = dtree_model.predict(x_norm_test)\n",
        "#print('Decision Tree',accuracy_score(y_test, dtree_predicted))\n",
        "print('Decision Tree',cross_val_score(dtree_model,pca_train_data, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#XGBOOST\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "xgb = XGBClassifier()\n",
        "#xgb.fit(x_norm_train,y_train.values.ravel())\n",
        "#xgb_predicted = xgb.predict(x_norm_test)\n",
        "#print('XGBoost',accuracy_score(y_test, xgb_predicted))\n",
        "print('XGBoost',cross_val_score(xgb,pca_train_data, train_labels.values.ravel(), cv=10).mean())"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Naive Bayes 0.8400000000000001\n",
            "KNN 0.907\n",
            "Random Forest 0.9059999999999999\n",
            "Logistic Regression 0.8210000000000001\n",
            "SVM 0.9029999999999999\n",
            "Decision Tree 0.797\n",
            "XGBoost 0.876\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_TsXNMvGAZ8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "outputId": "15119bb2-d499-4721-f50f-0b8161e5c900"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "x_all = np.r_[train_data,test_data]\n",
        "print('x_all shape :',x_all.shape)\n",
        "\n",
        "# USING THE GAUSSIAN MIXTURE MODEL \n",
        "lowest_bic = np.infty\n",
        "bic = []\n",
        "n_components_range = range(1, 7)\n",
        "cv_types = ['spherical', 'tied', 'diag', 'full']\n",
        "for cv_type in cv_types:\n",
        "    for n_components in n_components_range:\n",
        "        gmm = GaussianMixture(n_components=n_components,covariance_type=cv_type)\n",
        "        gmm.fit(x_all)\n",
        "        bic.append(gmm.aic(x_all))\n",
        "        if bic[-1] < lowest_bic:\n",
        "            lowest_bic = bic[-1]\n",
        "            best_gmm = gmm\n",
        "            \n",
        "best_gmm.fit(x_all)\n",
        "gmm_train = best_gmm.predict_proba(train_data)\n",
        "gmm_test = best_gmm.predict_proba(test_data)\n",
        "\n",
        "\n",
        "#Random Forest Classifier\n",
        "rfc = RandomForestClassifier(random_state=99)\n",
        "\n",
        "#USING GRID SEARCH\n",
        "n_estimators = [10, 50, 100, 200,400]\n",
        "max_depth = [3, 10, 20, 40]\n",
        "param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)\n",
        "\n",
        "grid_search_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv = 10,scoring='accuracy',n_jobs=-1).fit(gmm_train, train_labels.values.ravel())\n",
        "rfc_best = grid_search_rfc.best_estimator_\n",
        "print('Random Forest Best Score',grid_search_rfc.best_score_)\n",
        "print('Random Forest Best Parmas',grid_search_rfc.best_params_)\n",
        "print('Random Forest Accuracy',cross_val_score(rfc_best,gmm_train, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#KNN \n",
        "knn = KNeighborsClassifier()\n",
        "\n",
        "#USING GRID SEARCH\n",
        "n_neighbors=[3,5,6,7,8,9,10]\n",
        "param_grid = dict(n_neighbors=n_neighbors)\n",
        "\n",
        "grid_search_knn = GridSearchCV(estimator=knn, param_grid=param_grid, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train,train_labels.values.ravel())\n",
        "knn_best = grid_search_knn.best_estimator_\n",
        "print('KNN Best Score', grid_search_knn.best_score_)\n",
        "print('KNN Best Params',grid_search_knn.best_params_)\n",
        "print('KNN Accuracy',cross_val_score(knn_best,gmm_train, train_labels.values.ravel(), cv=10).mean())\n",
        "\n",
        "#SVM\n",
        "svc = SVC()\n",
        "\n",
        "#USING GRID SEARCH\n",
        "parameters = [{'kernel':['linear'],'C':[1,10,100]},\n",
        "              {'kernel':['rbf'],'C':[1,10,100],'gamma':[0.05,0.0001,0.01,0.001]}]\n",
        "grid_search_svm = GridSearchCV(estimator=svc, param_grid=parameters, cv = 10, n_jobs=-1,scoring='accuracy').fit(gmm_train, train_labels.values.ravel())\n",
        "svm_best = grid_search_svm.best_estimator_\n",
        "print('SVM Best Score',grid_search_svm.best_score_)\n",
        "print('SVM Best Params',grid_search_svm.best_params_)\n",
        "print('SVM Accuracy',cross_val_score(svm_best,gmm_train, train_labels.values.ravel(), cv=10).mean())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_all shape : (10000, 40)\n",
            "Random Forest Best Score 0.996\n",
            "Random Forest Best Parmas {'max_depth': 3, 'n_estimators': 10}\n",
            "Random Forest Accuracy 0.9960000000000001\n",
            "KNN Best Score 0.996\n",
            "KNN Best Params {'n_neighbors': 3}\n",
            "KNN Accuracy 0.9960000000000001\n",
            "SVM Best Score 0.996\n",
            "SVM Best Params {'C': 1, 'kernel': 'linear'}\n",
            "SVM Accuracy 0.9960000000000001\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwiGpnZCGAXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rfc_best.fit(gmm_train,train_labels.values.ravel())\n",
        "pred  = rfc_best.predict(gmm_test)\n",
        "rfc_best_pred = pd.DataFrame(pred)\n",
        "\n",
        "rfc_best_pred.index += 1\n",
        "\n",
        "rfc_best_pred.columns = ['Solution']\n",
        "rfc_best_pred['Id'] = np.arange(1,rfc_best_pred.shape[0]+1)\n",
        "rfc_best_pred = rfc_best_pred[['Id', 'Solution']]\n",
        "\n",
        "rfc_best_pred.to_csv('Submission_GMM_RFC.csv',index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oENLEYdBGAUk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iON_vhvGAOt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ea-AbvOiGANC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}